{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from visdom import Visdom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
    "\n",
    "        if self.unaligned:\n",
    "            t = random.randint(0, len(self.files_B) - 1)\n",
    "            img = Image.open(self.files_B[t]).convert('RGB')\n",
    "            # try:\n",
    "            item_B = self.transform(img)\n",
    "            # except:\n",
    "            #     print(img)\n",
    "        else:\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]).convert('RGB'))\n",
    "\n",
    "        return {'A': item_A, 'B': item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block       \n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, 64, 7),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.ReLU(inplace=True)]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                      nn.InstanceNorm2d(out_features),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(64, output_nc, 7),\n",
    "                  nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # A bunch of convolutions one after another\n",
    "        model = [nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "                 nn.LeakyReLU(0.2, inplace=True)]\n",
    "\n",
    "        model += [nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                  nn.InstanceNorm2d(128),\n",
    "                  nn.LeakyReLU(0.2, inplace=True)]\n",
    "\n",
    "        model += [nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "                  nn.InstanceNorm2d(256),\n",
    "                  nn.LeakyReLU(0.2, inplace=True)]\n",
    "\n",
    "        model += [nn.Conv2d(256, 512, 4, padding=1),\n",
    "                  nn.InstanceNorm2d(512),\n",
    "                  nn.LeakyReLU(0.2, inplace=True)]\n",
    "\n",
    "        # FCN classification layer\n",
    "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        # Average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2image(tensor):\n",
    "    image = 127.5 * (tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1:\n",
    "        image = np.tile(image, (3, 1, 1))\n",
    "    return image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, n_epochs, batches_epoch):\n",
    "        self.viz = Visdom()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batches_epoch = batches_epoch\n",
    "        self.epoch = 1\n",
    "        self.batch = 1\n",
    "        self.prev_time = time.time()\n",
    "        self.mean_period = 0\n",
    "        self.losses = {}\n",
    "        self.loss_windows = {}\n",
    "        self.image_windows = {}\n",
    "\n",
    "    def log(self, losses=None, images=None):\n",
    "        self.mean_period += (time.time() - self.prev_time)\n",
    "        self.prev_time = time.time()\n",
    "\n",
    "        sys.stdout.write(\n",
    "            '\\rEpoch %03d/%03d [%04d/%04d] -- ' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\n",
    "\n",
    "        for i, loss_name in enumerate(losses.keys()):\n",
    "            if loss_name not in self.losses:\n",
    "                self.losses[loss_name] = losses[loss_name].item()\n",
    "            else:\n",
    "                self.losses[loss_name] += losses[loss_name].item()\n",
    "\n",
    "            if (i + 1) == len(losses.keys()):\n",
    "                sys.stdout.write('%s: %.4f -- ' % (loss_name, self.losses[loss_name] / self.batch))\n",
    "            else:\n",
    "                sys.stdout.write('%s: %.4f | ' % (loss_name, self.losses[loss_name] / self.batch))\n",
    "\n",
    "        batches_done = self.batches_epoch * (self.epoch - 1) + self.batch\n",
    "        batches_left = self.batches_epoch * (self.n_epochs - self.epoch) + self.batches_epoch - self.batch\n",
    "        sys.stdout.write('ETA: %s' % (datetime.timedelta(seconds=batches_left * self.mean_period / batches_done)))\n",
    "\n",
    "        # Draw images\n",
    "        for image_name, tensor in images.items():\n",
    "            if image_name not in self.image_windows:\n",
    "                self.image_windows[image_name] = self.viz.image(tensor2image(tensor.data), opts={'title': image_name})\n",
    "            else:\n",
    "                self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name],\n",
    "                               opts={'title': image_name})\n",
    "\n",
    "        # End of epoch\n",
    "        if (self.batch % self.batches_epoch) == 0:\n",
    "            # Plot losses\n",
    "            for loss_name, loss in self.losses.items():\n",
    "                if loss_name not in self.loss_windows:\n",
    "                    self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]),\n",
    "                                                                 Y=np.array([loss / self.batch]),\n",
    "                                                                 opts={'xlabel': 'epochs', 'ylabel': loss_name,\n",
    "                                                                       'title': loss_name})\n",
    "                else:\n",
    "                    self.viz.line(X=np.array([self.epoch]), Y=np.array([loss / self.batch]),\n",
    "                                  win=self.loss_windows[loss_name], update='append')\n",
    "                # Reset losses for next epoch\n",
    "                self.losses[loss_name] = 0.0\n",
    "\n",
    "            self.epoch += 1\n",
    "            self.batch = 1\n",
    "            sys.stdout.write('\\n')\n",
    "        else:\n",
    "            self.batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.n_epochs=200\n",
    "        self.batchSize=1\n",
    "        self.dataroot='./datasets/data/'\n",
    "        self.lr=0.0002\n",
    "        self.decay_epoch=100\n",
    "        self.size=256\n",
    "        self.input_nc=3\n",
    "        self.output_nc=3\n",
    "        self.cuda=False\n",
    "        self.n_cpu=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = OPT()\n",
    "\n",
    "    if torch.cuda.is_available() and not opt.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "    ###### Definition of variables ######\n",
    "    # Networks\n",
    "    if opt.cuda:\n",
    "        netG_A2B = torch.nn.DataParallel(Generator(opt.input_nc, opt.output_nc))\n",
    "        netG_B2A =  torch.nn.DataParallel(Generator(opt.output_nc, opt.input_nc))\n",
    "        netD_A = torch.nn.DataParallel(Discriminator(opt.input_nc))\n",
    "        netD_B = torch.nn.DataParallel(Discriminator(opt.output_nc))\n",
    "\n",
    "        netG_A2B.cuda()\n",
    "        netG_B2A.cuda()\n",
    "        netD_A.cuda()\n",
    "        netD_B.cuda()\n",
    "    else:\n",
    "        netG_A2B = torch.nn.DataParallel(Generator(opt.input_nc, opt.output_nc))\n",
    "        netG_B2A =  torch.nn.DataParallel(Generator(opt.output_nc, opt.input_nc))\n",
    "        netD_A = torch.nn.DataParallel(Discriminator(opt.input_nc))\n",
    "        netD_B = torch.nn.DataParallel(Discriminator(opt.output_nc))\n",
    "\n",
    "    netG_A2B.apply(weights_init_normal)\n",
    "    netG_B2A.apply(weights_init_normal)\n",
    "    netD_A.apply(weights_init_normal)\n",
    "    netD_B.apply(weights_init_normal)\n",
    "\n",
    "    # Lossess\n",
    "    criterion_GAN = torch.nn.MSELoss()\n",
    "    criterion_cycle = torch.nn.L1Loss()\n",
    "    criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "    # Optimizers & LR schedulers\n",
    "    optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                   lr=opt.lr, betas=(0.5, 0.999))\n",
    "    optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "    optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "\n",
    "    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,\n",
    "                                                                                       opt.decay_epoch).step)\n",
    "    lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,\n",
    "                                                                                           opt.decay_epoch).step)\n",
    "    lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch,\n",
    "                                                                                           opt.decay_epoch).step)\n",
    "\n",
    "    # Inputs & targets memory allocation\n",
    "    Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "    input_A = Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "    input_B = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "    target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)\n",
    "    target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "    fake_A_buffer = ReplayBuffer()\n",
    "    fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "    # Dataset loader\n",
    "    transforms_ = [transforms.Resize(int(opt.size * 1.12), Image.BICUBIC),\n",
    "                   transforms.RandomCrop(opt.size),\n",
    "                   transforms.RandomHorizontalFlip(),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True),\n",
    "                            batch_size=opt.batchSize, shuffle=True, num_workers=opt.n_cpu)\n",
    "\n",
    "    # Loss plot\n",
    "    logger = Logger(opt.n_epochs, len(dataloader))\n",
    "    ###################################\n",
    "\n",
    "    ###### Training ######\n",
    "    for epoch in range(opt.epoch, opt.n_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Set model input\n",
    "            real_A = Variable(input_A.copy_(batch['A']))\n",
    "            real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "            ###### Generators A2B and B2A ######\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Identity loss\n",
    "            # G_A2B(B) should equal B if real B is fed\n",
    "            same_B = netG_A2B(real_B)\n",
    "            loss_identity_B = criterion_identity(same_B, real_B) * 5.0\n",
    "            # G_B2A(A) should equal A if real A is fed\n",
    "            same_A = netG_B2A(real_A)\n",
    "            loss_identity_A = criterion_identity(same_A, real_A) * 5.0\n",
    "\n",
    "            # GAN loss\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            pred_fake = netD_B(fake_B)\n",
    "            loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            fake_A = netG_B2A(real_B)\n",
    "            pred_fake = netD_A(fake_A)\n",
    "            loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "            # Cycle loss\n",
    "            recovered_A = netG_B2A(fake_B)\n",
    "            loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * 10.0\n",
    "\n",
    "            recovered_B = netG_A2B(fake_A)\n",
    "            loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "            # Total loss\n",
    "            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "            loss_G.backward()\n",
    "\n",
    "            optimizer_G.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator A ######\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_A(real_A)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "            pred_fake = netD_A(fake_A.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator B ######\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_B(real_B)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "            pred_fake = netD_B(fake_B.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "            ###################################\n",
    "\n",
    "            # Progress report (http://localhost:8097)\n",
    "            logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B),\n",
    "                        'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
    "                        'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)},\n",
    "                       images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
    "\n",
    "        # Update learning rates\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_A.step()\n",
    "        lr_scheduler_D_B.step()\n",
    "\n",
    "        # Save models checkpoints\n",
    "        torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\n",
    "        torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\n",
    "        torch.save(netD_A.state_dict(), 'output/netD_A.pth')\n",
    "        torch.save(netD_B.state_dict(), 'output/netD_B.pth')\n",
    "    ###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-35fc5b1c97d0>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n\u001b[0;32m     64\u001b[0m     dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True),\n\u001b[1;32m---> 65\u001b[1;33m                             batch_size=opt.batchSize, shuffle=True, num_workers=opt.n_cpu)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Loss plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# map-style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[1;32m---> 94\u001b[1;33m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
